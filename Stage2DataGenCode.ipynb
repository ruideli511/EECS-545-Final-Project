{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "757e54d7",
   "metadata": {
    "id": "757e54d7"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import re\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "UPLUGq5mTPqy",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UPLUGq5mTPqy",
    "outputId": "99c12b14-e1e0-4459-a4ad-80d725d01302"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38496\n"
     ]
    }
   ],
   "source": [
    "img_dir = r'C:\\Users\\stbyu\\Desktop\\University of Michigan\\CurrQuarter\\EECS 545\\FinalProject\\train'\n",
    "search_path = os.path.join(img_dir, \"**\",  \"*.png\")\n",
    "files = glob.glob(search_path, recursive=True)\n",
    "img_files = [f.replace('\\\\', '/') for f in files]\n",
    "print(len(img_files))\n",
    "\n",
    "#img_files = img_files[28000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7aeb3b6",
   "metadata": {
    "id": "e7aeb3b6"
   },
   "outputs": [],
   "source": [
    "def pad_image(img_arr, height, width):\n",
    "    # Calculate the amount of padding needed\n",
    "    h, w = img_arr.shape[:2]\n",
    "    pad_h = max(0, height - h)\n",
    "    pad_w = max(0, width - w)\n",
    "\n",
    "    # Add padding to the image\n",
    "    padded_arr = np.pad(img_arr, ((0, pad_h), (0, pad_w)), mode='constant', constant_values=0)\n",
    "    return(padded_arr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "SQzQNmIHT25x",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SQzQNmIHT25x",
    "outputId": "6e307753-cb92-4a5e-8850-4f2722b92642"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n"
     ]
    }
   ],
   "source": [
    "filename = []\n",
    "maxh = 310\n",
    "maxw = 360\n",
    "image_data = np.zeros((len(img_files), maxh, maxw),dtype=np.uint8)\n",
    "shape = []\n",
    "\n",
    "for i,img_path in enumerate(img_files):\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) # Convert to grayscale\n",
    "    img_np = np.asarray(img)\n",
    "    label1 = re.search(r'case[\\d]+_day[\\d]+', img_path)\n",
    "    label2 = re.search(r'slice_[\\d]+', img_path)\n",
    "    tmp_list = img_path.split('_')\n",
    "    shape.append((int(tmp_list[4]), int(tmp_list[3])))\n",
    "    fn = label1[0]+\"_\"+label2[0]\n",
    "    image_data[i] = pad_image(img_np, maxh, maxw)\n",
    "    filename.append(fn)\n",
    "    if (i%1000 == 0):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df8728d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_shape = len(img_files) /2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ffc173a",
   "metadata": {
    "id": "8ffc173a"
   },
   "outputs": [],
   "source": [
    "tmp_shape = int(tmp_shape)\n",
    "img2_5D = np.zeros((tmp_shape, 3, maxh, maxw), dtype = int)\n",
    "labels = np.zeros((tmp_shape, 3, maxh, maxw), dtype = int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "WSXRBZUWcjiA",
   "metadata": {
    "id": "WSXRBZUWcjiA"
   },
   "outputs": [],
   "source": [
    "def rle_decode(mask_rle, shape=(768, 768)):\n",
    "    '''\n",
    "    mask_rle: run-length as string formated (start length)\n",
    "    shape: (height,width) of array to return\n",
    "    Returns numpy array, 1 - mask, 0 - background\n",
    "    '''\n",
    "    if not isinstance(mask_rle, str):\n",
    "        img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "        return img.reshape(shape)\n",
    "\n",
    "    s = mask_rle.split()\n",
    "    s = s[1:]\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "    return img.reshape(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "p_ktBXklYyjl",
   "metadata": {
    "id": "p_ktBXklYyjl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "1000 418\n",
      "2000 898\n",
      "3000 1359\n",
      "4000 1806\n",
      "5000 2345\n",
      "6000 2763\n",
      "7000 3257\n",
      "8000 3709\n",
      "9000 4202\n",
      "10000 4669\n",
      "11000 5172\n",
      "12000 5650\n",
      "13000 6073\n",
      "14000 6543\n",
      "15000 6950\n",
      "16000 7308\n",
      "17000 7692\n",
      "18000 8092\n",
      "19000 8495\n",
      "20000 9025\n",
      "21000 9517\n",
      "22000 9845\n",
      "23000 10235\n",
      "24000 10700\n",
      "25000 11235\n",
      "26000 11646\n",
      "27000 12118\n",
      "28000 12548\n",
      "29000 12991\n",
      "30000 13365\n",
      "31000 13775\n",
      "32000 14199\n",
      "33000 14486\n",
      "34000 14797\n",
      "35000 15170\n",
      "36000 15523\n",
      "37000 15874\n",
      "38000 16361\n"
     ]
    }
   ],
   "source": [
    "path = r'C:\\Users\\stbyu\\Desktop\\University of Michigan\\CurrQuarter\\EECS 545\\FinalProject\\train\\train.csv'\n",
    "path = path.replace('\\\\', '/')\n",
    "df = pd.read_csv(path)\n",
    "pd.options.display.max_colwidth = None\n",
    "j = 0\n",
    "for i in range(len(img_files)):\n",
    "    if (i % 1000 ==0):\n",
    "        print(i, j)\n",
    "    # process the img2.5D\n",
    "    if (i == 0 or i == len(img_files) - 1):\n",
    "        continue\n",
    "    pre_sn = re.search(r\"(\\w+_\\w+)_slice\", filename[i-1]).group(1)\n",
    "    curr_sn = re.search(r\"(\\w+_\\w+)_slice\", filename[i]).group(1)\n",
    "    next_sn = re.search(r\"(\\w+_\\w+)_slice\", filename[i+1]).group(1)\n",
    "    if (pre_sn.lower() != curr_sn.lower()):\n",
    "        continue\n",
    "    if(next_sn.lower() != curr_sn.lower()):\n",
    "        continue\n",
    "        \n",
    "    img2_5D[j,1,:,:] = image_data[i]\n",
    "    img2_5D[j,0,:,:] = image_data[i-1]\n",
    "    img2_5D[j,2,:,:] = image_data[i+1]\n",
    "\n",
    "  # process the masks aka labels\n",
    "    fn = filename[i]\n",
    "    valid = 0\n",
    "    filtered_df = df[(df['id'] == fn) & (df['class'] == 'large_bowel')]\n",
    "    if (not filtered_df[\"segmentation\"].isna().all()):\n",
    "        valid = 1\n",
    "        labels[j,0,:,:] = pad_image(rle_decode(filtered_df[\"segmentation\"].to_string(), shape[i]), maxh, maxw)\n",
    "    \n",
    "    filtered_df = df[(df['id'] == fn) & (df['class'] == 'small_bowel')]\n",
    "    if (not filtered_df[\"segmentation\"].isna().all()):\n",
    "        valid = 1\n",
    "        labels[j,1,:,:] = pad_image(rle_decode(filtered_df[\"segmentation\"].to_string(), shape[i]), maxh, maxw)\n",
    "    \n",
    "    filtered_df = df[(df['id'] == fn) & (df['class'] == 'stomach')]\n",
    "    if (not filtered_df[\"segmentation\"].isna().all()):\n",
    "        valid = 1\n",
    "        labels[j,2,:,:] = pad_image(rle_decode(filtered_df[\"segmentation\"].to_string(), shape[i]), maxh, maxw)\n",
    "    \n",
    "    if (valid):\n",
    "        j = j + 1\n",
    "    if (j >= len(img_files)/2): \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d281656f",
   "metadata": {},
   "outputs": [],
   "source": [
    "img2_5D = img2_5D[:j, :,:,:]\n",
    "labels = labels[:j, :, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3f06ac4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"New_input_data.npy\", img2_5D)\n",
    "np.save(\"New_label_data.npy\", labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "06bbe725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.43095386533665836\n"
     ]
    }
   ],
   "source": [
    "print(j / len(img_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ba29e192",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_dataset(data, labels, train_ratio=0.7, val_ratio=0.2, test_ratio=0.1):\n",
    "#     if train_ratio + val_ratio + test_ratio != 1.0:\n",
    "#         raise ValueError(\"The sum of ratios must be equal to 1\")\n",
    "\n",
    "    # Split data into training and temp sets (validation + testing)\n",
    "    train_data, temp_data, train_labels, temp_labels = train_test_split(\n",
    "        data, labels, train_size=train_ratio, random_state=545\n",
    "    )\n",
    "\n",
    "    # Calculate the ratio of validation set relative to the temp set (validation + testing)\n",
    "    relative_val_ratio = val_ratio / (val_ratio + test_ratio)\n",
    "\n",
    "    # Split the temp set into validation and testing sets\n",
    "    val_data, test_data, val_labels, test_labels = train_test_split(\n",
    "        temp_data, temp_labels, train_size=relative_val_ratio, random_state=545\n",
    "    )\n",
    "\n",
    "    return (train_data, train_labels), (val_data, val_labels), (test_data, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d618cf53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# indices = np.random.permutation(j)\n",
    "# training_idx, val_idx, test_idx = indices[:int(0.7*j)], indices[int(0.7*j):int(0.9*j)], indices[int(0.9*j):] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cc543d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = [...]  # Your dataset features\n",
    "# labels = [...]  # Your dataset labels\n",
    "(train_data, train_labels), (val_data, val_labels), (test_data, test_labels) = split_dataset(img2_5D, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "db4636e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16590, 3, 310, 360) (16590, 3, 310, 360)\n"
     ]
    }
   ],
   "source": [
    "print(img2_5D.shape, labels.shape)\n",
    "# np.save(\"train/undivided_data_2.npy\", img2_5D)\n",
    "# np.save(\"train/undivided_label_2.npy\", labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa28f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_data, val_data, test_data = img2_5D[training_idx, :,:,:], img2_5D[val_idx, :,:,:], img2_5D[test_idx, :,:,:] \n",
    "# training_label, val_label, test_label = labels[training_idx, :,:,:], labels[val_idx, :,:,:], labels[test_idx, :,:,:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e6617f18",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e6617f18",
    "outputId": "609e15ba-2237-4786-8b41-296d7ba490b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11613, 3, 310, 360) (3318, 3, 310, 360) (1659, 3, 310, 360)\n",
      "(11613, 3, 310, 360) (3318, 3, 310, 360) (1659, 3, 310, 360)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape, val_data.shape, test_data.shape)\n",
    "print(train_labels.shape, val_labels.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6cc705e6",
   "metadata": {
    "id": "6cc705e6"
   },
   "outputs": [],
   "source": [
    "np.save(\"train_input.npy\", train_data)\n",
    "np.save(\"val_input.npy\", val_data)\n",
    "np.save(\"test_input.npy\", test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "76daf078",
   "metadata": {
    "id": "76daf078"
   },
   "outputs": [],
   "source": [
    "np.save(\"train_labels.npy\", train_labels)\n",
    "np.save(\"val_labels.npy\", val_labels)\n",
    "np.save(\"test_labels.npy\", test_labels)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
